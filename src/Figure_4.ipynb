{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_fourier_transform\n",
    "import graph_ruggedness_de\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making KNN graph over GB1 combinatorial dataset \n",
    "The below cell is run to make build to KNN graph for the gb1 combinatorial dataset. Note that the `approximate` method is used to find the `k` nearest neighbors due to the time complexity of an exact all vs. all search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data_files/gb1_dat_comb.csv')\n",
    "seq_ls = df['sequences'].tolist()\n",
    "values = df['fitness'].tolist()\n",
    "scaler = MinMaxScaler()\n",
    "values = [val[0] for val in (scaler.fit_transform(np.array(values).reshape(-1,1)))]\n",
    "\n",
    "G_k = graph_ruggedness_de.build_ohe_graph(seq_ls=seq_ls,\n",
    "                                        values=values,\n",
    "                                        edges=False,\n",
    "                                        hamming_edges=False, \n",
    "                                        approximate=True,\n",
    "                                        n=400)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Dirichlet energies over subgraphs \n",
    "The below cell is run to sample the Dirichlet energy (approximate method due to comp. complexity) over subgraphs with random sampling proportions defined in `sampling_props` for replicates defined in `replicates`. This indicates how robust quantification of ruggedness via Dirichlet energy is to incomplete graphs. The Dirichlet energy is scaled by the ration between the square-root of the number of nodes in the full graph and the square root of the number of nodes in the sampled graph, as the energy is calculated over the number of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_props = [0.1, 0.2, 0.5, 0.75, 0.999]\n",
    "replicates = 10\n",
    "nodes = G_k.number_of_nodes()\n",
    "norm_de_dict = {}\n",
    "\n",
    "for sampling_prop in sampling_props:\n",
    "    norm_de = []\n",
    "    gft_coefficients = []\n",
    "    scaling_factor = np.sqrt(nodes) / np.sqrt(nodes*sampling_prop)\n",
    "    for _ in range(replicates):\n",
    "\n",
    "        G_sampled, sampled_nodes, sampled_values = graph_ruggedness_de.sample_graph(G=G_k,\n",
    "                                                                                    sample_size=sampling_prop)\n",
    "        graph_ruggedness_de.add_ohe_knn_edges_approx(G=G_sampled,\n",
    "                                                     k=int(np.sqrt(G_sampled.number_of_nodes())))\n",
    "        sampled_de = graph_ruggedness_de.compute_dirichlet_energy_approximate(G=G_sampled)\n",
    "        sampled_de = sampled_de / G_sampled.number_of_nodes()\n",
    "        sampled_de = sampled_de * scaling_factor\n",
    "        norm_de.append(sampled_de)\n",
    "    norm_de_dict[sampling_prop] = np.array(norm_de)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the full KNN graph to determine the actual Dirichlet energy when it is 100% sampled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_k = graph_ruggedness_de.build_ohe_graph(seq_ls=seq_ls,\n",
    "                                        values=values,\n",
    "                                        edges=True,\n",
    "                                        hamming_edges=False, \n",
    "                                        approximate=True,\n",
    "                                        n=400)\n",
    "de = graph_ruggedness_de.compute_dirichlet_energy_approximate(G=G_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = [key for key in norm_de_dict.keys()]\n",
    "vals = [norm_de_dict[key] for key in norm_de_dict.keys()]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2.5,2.75))\n",
    "bp = ax.boxplot(vals, labels=[str(label) for label in labs], notch=False, patch_artist=True)\n",
    "\n",
    "# Set fill colors for each box\n",
    "color = 'grey'\n",
    "for box in bp['boxes']:\n",
    "    box.set_facecolor(color)\n",
    "\n",
    "# Set median line color\n",
    "for median in bp['medians']:\n",
    "    median.set_color('black')\n",
    "plt.axhline(de / G_k.number_of_nodes(), color='grey', linestyle='--')\n",
    "\n",
    "plt.ylim(0,1.5)\n",
    "plt.ylabel('Normalised Dirichlet energy')\n",
    "plt.xlabel('Sampling proportion')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/Figure_4/sampling_boxplot.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of the graph, ruggedness and epistasis over different sampling proportions. \n",
    "Different sampling proportions may influence the interpretation of epistasis / ruggedness over the fitness map. Analysing the graph structures, and their local Dirichlet Energies returned through graph sampling is important in understanding how significantly graph sampling can change the biological / biophysical interpretation of these phenomena. For example - does the graph need to be complete to gain an overview of epistasis and ruggedness in that fitness map? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GFT sums\n",
    "\n",
    "First - this can be tested quantitatively by comparing the cumulative sum the magnitudes from the GFT, when they have been normalised to sum to 1 and the eigenvector indices have been normalised to sum to 1, over both the full GB1 landscape graph and the subsampled GB1 landscape graph (with replication). If the trace of the full GB1 landscape is not significantly different from the distribution of subsampled traces, the information is not meaningfully lost when the graph nodes are subsampled. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualitative local Dirichlet Energy analysis\n",
    "The second approach is a qualitative analysis of the local Dirichlet energy over nodes in both the full and subsampled GFT landscape graphs. If subsampling retains the relative rank of locally rugged nodes, then the biophysical interpretation of epistasis and ruggedness is robust to hamming incomplete graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data_files/gb1_dat_comb.csv')\n",
    "seq_ls = df['sequences'].tolist()\n",
    "values = df['fitness'].tolist()\n",
    "scaler = MinMaxScaler()\n",
    "values = [val[0] for val in (scaler.fit_transform(np.array(values).reshape(-1,1)))]\n",
    "\n",
    "G_k_con = graph_ruggedness_de.build_ohe_graph(seq_ls=seq_ls,\n",
    "                                        values=values,\n",
    "                                        edges=True,\n",
    "                                        hamming_edges=False, \n",
    "                                        approximate=True,\n",
    "                                        n=400)\n",
    "\n",
    "G_k = graph_ruggedness_de.build_ohe_graph(seq_ls=seq_ls,\n",
    "                                        values=values,\n",
    "                                        edges=False,\n",
    "                                        hamming_edges=False, \n",
    "                                        approximate=True,\n",
    "                                        n=400)\n",
    "\n",
    "sampling_prop = 0.1\n",
    "G_sampled, sampled_nodes, sampled_values = graph_ruggedness_de.sample_graph(G=G_k,\n",
    "                                                                            sample_size=sampling_prop)\n",
    "graph_ruggedness_de.add_ohe_knn_edges_approx(G=G_sampled,\n",
    "                                                k=int(np.sqrt(G_sampled.number_of_nodes())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_ruggedness_de.compute_local_dirichlet_energy(G=G_sampled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: the following cell requires > 3 hours to compute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_ruggedness_de.compute_local_dirichlet_energy(G=G_k_con,\n",
    "                                                   approximate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_prop = 0.1\n",
    "nodes = G_k.number_of_nodes()\n",
    "\n",
    "scaling_factor = np.sqrt(nodes) / np.sqrt(nodes*sampling_prop)\n",
    "G_sampled, sampled_nodes, sampled_values = graph_ruggedness_de.sample_graph(G=G_k,\n",
    "                                                                            sample_size=sampling_prop)\n",
    "graph_ruggedness_de.add_ohe_knn_edges_approx(G=G_sampled,\n",
    "                                            k=int(np.sqrt(G_sampled.number_of_nodes())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_ruggedness_de.compute_local_dirichlet_energy(G=G_sampled,\n",
    "                                                   approximate=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Dirichlet energy over different degrees of incidence\n",
    "Different degrees of incidence, sampled with `sample_graph_degree`, can be used to gain insight on the contributions of epistasis of n degrees / edges. \n",
    "\n",
    "### Epistasis as a function of ruggedness\n",
    "Starting from a reference node (sequence in the graph), the change in ruggedness as a function of incidence provides insight on the linearity of the fitness function over the system. For example, if the dirichlet energy remains unchanged as the degree increases from a reference node, the fitness of the reference node is not confounded by epistasis. If It linearly increases, the fitness of the reference node is influenced equally by each degree of the graph. If it increases non-linearly, the curvature over the degree can be measured as the sum of discretised second derivatives at each point. If the sum of second derivatives if positive, then non-linearity is injected disproportionately by one degree in the graph. Therefore, the epistasis (or a measurement of it) over a n edge degrees can be described by two values: the gradient in energy over the first through nth degree of the graph (with respect to a particular node) and the curvatrue, or sum of second derivatives. The distribution of these values give insight on the isotropy of the fitness landscape: if there is a wide spread of values, the landscape is anisotropic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data_files/gb1_dat_comb.csv')\n",
    "seq_ls = df['sequences'].tolist()\n",
    "values = df['fitness'].tolist()\n",
    "scaler = MinMaxScaler()\n",
    "values = [val[0] for val in (scaler.fit_transform(np.array(values).reshape(-1,1)))]\n",
    "\n",
    "G_k = graph_ruggedness_de.build_ohe_graph(seq_ls=seq_ls,\n",
    "                                        values=values,\n",
    "                                        edges=True,\n",
    "                                        hamming_edges=False, \n",
    "                                        approximate=True,\n",
    "                                        n=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_k_de = graph_ruggedness_de.compute_dirichlet_energy_approximate(G=G_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replicates = 50\n",
    "degree_dict = {}\n",
    "for replicate in range(replicates):\n",
    "    avg_diffs = []\n",
    "    G_sampled, ref_node, de_degree= graph_ruggedness_de.sample_graph_degree(G=G_k,\n",
    "                                                        degree=3, \n",
    "                                                        compute_de=True,\n",
    "                                                        approximate=True)\n",
    "    \n",
    "    diff_ls = graph_ruggedness_de.count_seq_diff(ref_node=ref_node,\n",
    "                                                    node_ls=[node for node in G_sampled.nodes()])\n",
    "    avg_diffs.append(np.mean(diff_ls))\n",
    "    degree_dict[replicate] = (de_degree, np.array(avg_diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2.5,2.75))\n",
    "x_labs = list(range(1,5))\n",
    "for i in range(50):\n",
    "    vals = [val for val in degree_dict[i][0].values()]\n",
    "    vals.append(G_k_de / G_k.number_of_nodes())\n",
    "    ax.plot(x_labs, vals, color='grey', linestyle='--', linewidth=0.75, alpha=0.35)\n",
    "plt.xlabel('Distance from ref. (edges)')\n",
    "plt.ylabel('Normalised Dirichlet energy')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/Figure_4/de_vs_degree_plot.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(1.75,1.75))\n",
    "\n",
    "first_derivative = []\n",
    "second_derivative = []\n",
    "for i in range(50):\n",
    "    vals = [val for val in degree_dict[i][0].values()]\n",
    "    vals.append(G_k_de / G_k.number_of_nodes())\n",
    "    derivatives = [vals[i+1] - vals[i] for i in range(len(vals) - 1)]\n",
    "    first_derivative.append(sum(derivatives))\n",
    "    second_derivatives = [derivatives[i+1] - derivatives[i] for i in range(len(derivatives) - 1)]\n",
    "    second_derivative.append(sum(second_derivatives))\n",
    "\n",
    "plt.hist(first_derivative, bins=10, color='grey', edgecolor='black')\n",
    "plt.xlabel('Gradient')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/Figure_4/gradient_hist_full.pdf')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(1.75,1.75))\n",
    "plt.hist(second_derivative, bins=10, color='grey', edgecolor='black')\n",
    "plt.xlabel('Curvature')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/Figure_4/curvature_hist_full.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epistasis as a function of ruggedness over incomplete fitness maps \n",
    "Measuring epistasis as the gradient and curvature of ruggedness with respect to the degree from a reference node should be (approximately) reproducible between subsampled and complete network Graphs. This can be tested by repeating the previous analyses in subsampled graphs. \n",
    "\n",
    "#### Note: the following cells each take > 4 hours to compute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_prop = 0.1\n",
    "nodes = G_k.number_of_nodes()\n",
    "sampling_reps = 5\n",
    "degree_dict_01_ls = []\n",
    "de_full_01 = {}\n",
    "for sampling_replicate in range(sampling_reps):\n",
    "\n",
    "    scaling_factor = np.sqrt(nodes) / np.sqrt(nodes*sampling_prop)\n",
    "    G_sampled, sampled_nodes, sampled_values = graph_ruggedness_de.sample_graph(G=G_k,\n",
    "                                                                                sample_size=sampling_prop)\n",
    "    graph_ruggedness_de.add_ohe_knn_edges_approx(G=G_sampled,\n",
    "                                                k=int(np.sqrt(G_sampled.number_of_nodes())))\n",
    "    G_sampled_de = graph_ruggedness_de.compute_dirichlet_energy_approximate(G_sampled) / G_sampled.number_of_nodes()\n",
    "    de_full_01[sampling_replicate] = G_sampled_de\n",
    "\n",
    "    replicates = 10\n",
    "    degree_dict_01 = {}\n",
    "    for replicate in range(replicates):\n",
    "        avg_diffs = []\n",
    "        G_sampled, ref_node, de_degree= graph_ruggedness_de.sample_graph_degree(G=G_sampled,\n",
    "                                                            degree=3, \n",
    "                                                            compute_de=True,\n",
    "                                                            approximate=True)\n",
    "        diff_ls = graph_ruggedness_de.count_seq_diff(ref_node=ref_node,\n",
    "                                                        node_ls=[node for node in G_sampled.nodes()])\n",
    "        avg_diffs.append(np.mean(diff_ls))\n",
    "        degree_dict_01[replicate] = (de_degree, np.array(avg_diffs))\n",
    "        degree_dict_01_ls.append(degree_dict_01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(1.75,1.75))\n",
    "\n",
    "first_derivative = []\n",
    "second_derivative = []\n",
    "for i in range(5):\n",
    "    for j in range(10):\n",
    "        vals = [val for val in degree_dict_01_ls[i][j][0].values()]\n",
    "        vals.append(de_full_01[i])\n",
    "        ax.plot(vals, color='grey', linestyle='--', linewidth=0.75, alpha=0.35)\n",
    "        derivatives = [vals[i+1] - vals[i] for i in range(len(vals) - 1)]\n",
    "        first_derivative.append(sum(derivatives))\n",
    "        second_derivatives = [derivatives[i+1] - derivatives[i] for i in range(len(derivatives) - 1)]\n",
    "        second_derivative.append(sum(second_derivatives))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(1.75,1.75))\n",
    "\n",
    "plt.hist(first_derivative, bins=10, color='grey', edgecolor='black')\n",
    "plt.xlabel('Gradient')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(1.75,1.75))\n",
    "plt.hist(second_derivative, bins=10, color='grey', edgecolor='black')\n",
    "plt.xlabel('Curvature')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_prop = 0.5\n",
    "nodes = G_k.number_of_nodes()\n",
    "sampling_reps = 5\n",
    "degree_dict_05_ls = []\n",
    "de_full_05 = {}\n",
    "for sampling_replicate in range(sampling_reps):\n",
    "\n",
    "    scaling_factor = np.sqrt(nodes) / np.sqrt(nodes*sampling_prop)\n",
    "    G_sampled, sampled_nodes, sampled_values = graph_ruggedness_de.sample_graph(G=G_k,\n",
    "                                                                                sample_size=sampling_prop)\n",
    "    G_sampled_de = graph_ruggedness_de.compute_dirichlet_energy_approximate(G_sampled) / G_sampled.number_of_nodes()\n",
    "    de_full_05[sampling_replicate] = G_sampled_de\n",
    "    graph_ruggedness_de.add_ohe_knn_edges_approx(G=G_sampled,\n",
    "                                                k=int(np.sqrt(G_sampled.number_of_nodes())))\n",
    "    replicates = 10\n",
    "    degree_dict_05 = {}\n",
    "    for replicate in range(replicates):\n",
    "        avg_diffs = []\n",
    "        G_sampled, ref_node, de_degree= graph_ruggedness_de.sample_graph_degree(G=G_sampled,\n",
    "                                                            degree=3, \n",
    "                                                            compute_de=True,\n",
    "                                                            approximate=True)\n",
    "        diff_ls = graph_ruggedness_de.count_seq_diff(ref_node=ref_node,\n",
    "                                                        node_ls=[node for node in G_sampled.nodes()])\n",
    "        avg_diffs.append(np.mean(diff_ls))\n",
    "        degree_dict_05[replicate] = (de_degree, np.array(avg_diffs))\n",
    "        degree_dict_05_ls.append(degree_dict_05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(1.75,1.75))\n",
    "\n",
    "first_derivative = []\n",
    "second_derivative = []\n",
    "for i in range(5):\n",
    "    for j in range(10):\n",
    "        vals = [val for val in degree_dict_05_ls[i][j][0].values()]\n",
    "        vals.append(de_full_05[i])\n",
    "        ax.plot(vals, color='grey', linestyle='--', linewidth=0.75, alpha=0.35)\n",
    "        derivatives = [vals[i+1] - vals[i] for i in range(len(vals) - 1)]\n",
    "        first_derivative.append(sum(derivatives))\n",
    "        second_derivatives = [derivatives[i+1] - derivatives[i] for i in range(len(derivatives) - 1)]\n",
    "        second_derivative.append(sum(second_derivatives))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(1.75,1.75))\n",
    "\n",
    "plt.hist(first_derivative, bins=10, color='grey', edgecolor='black')\n",
    "plt.xlabel('Gradient')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(1.75,1.75))\n",
    "plt.hist(second_derivative, bins=10, color='grey', edgecolor='black')\n",
    "plt.xlabel('Curvature')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = []\n",
    "for i in range(5):\n",
    "    for j in range(10):\n",
    "        vals_sample = [val for val in degree_dict_05_ls[i][j][0].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(1.75,1.75))\n",
    "\n",
    "first_derivative = []\n",
    "second_derivative = []\n",
    "for i in range(10):\n",
    "    for j in range(5):\n",
    "        vals = [val for val in degree_dict_05_ls[i][j][0].values()]\n",
    "        ax.plot(vals, color='grey', linestyle='--', linewidth=0.75, alpha=0.35)\n",
    "        derivatives = [vals[i+1] - vals[i] for i in range(len(vals) - 1)]\n",
    "        first_derivative.append(sum(derivatives))\n",
    "        second_derivatives = [derivatives[i+1] - derivatives[i] for i in range(len(derivatives) - 1)]\n",
    "        second_derivative.append(sum(second_derivatives))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(1.75,1.75))\n",
    "\n",
    "plt.hist(first_derivative, bins=10, color='grey', edgecolor='black')\n",
    "plt.xlabel('Gradient')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(1.75,1.75))\n",
    "plt.hist(second_derivative, bins=10, color='grey', edgecolor='black')\n",
    "plt.xlabel('Curvature')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_dict_05_ls[i][j-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [node[1]['value'] for node in G_sampled.nodes(data=True)]\n",
    "viridis = plt.cm.get_cmap('viridis', 10)\n",
    "node_colors = [viridis((value - min(values)) / (max(values) - min(values))) for value in values]\n",
    "nx.draw(G_sampled, node_color=node_colors, with_labels=False, edgecolors='black', node_size=100, width=0.75, edge_color='grey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_k.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
